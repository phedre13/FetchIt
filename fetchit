#!/usr/bin/python2.7

###
# I am fully aware that there is a bunch of bad in this.
# This script was originally an on-the-fly grabber for one specific task, so the hardcoding was relevant to the task and acceptable for the time being.
# My choice to move this into public domain was made partially for CONSTRUCTIVE criticism.
# Don't tell me how I'm stupid.  Help me learn by offering legitimate responses to things that I know are not quite correct in this script.
# Have fun.  Don't get in trouble!
###

import urllib2
import re
import sys
import csv
import os

# In the future, this will be where we grab search parameters for the user.
def RunProgram():
    global yourDir
    global stem

    FetchMain()
    FindNumbers()
    FindTV()
    CreateHexesFiles()
    ParseHexesFiles()
    DestroyFiles()

def UserUsesProgram():

    disclaimer = raw_input('This scraper was not intended for illegal activities.  If you choose to manipulate this script such that it is usable for such things, it is no longer the Intellectual Property of Succubus Softwares/Jessica Awtry.  Please, press y to continue or n to terminate the script.')
    userConfirms = disclaimer.strip().lower()

    if userConfirms == 'y':
        return True
    else:
        return False

# Grab the source code for the start-point page.  It is in turn used to locate the secondary set of pages.
def FetchMain():
    global stem
    userAgrees = UserUsesProgram()

    if userAgrees is False:
        DestroyFiles()
        sys.exit(0)

    else:
    	stem = raw_input('Please, enter the main url stem from which you wish to parse information.')
        #The url for mainResponse will eventually become a user-defined, string variable.
        mainResponse = urllib2.urlopen(stem)
        mainPage = mainResponse.read()
        print mainPage
        #Assigns the True/False returned by VerifyFetch to the variable userConfirms.
        userConfirms = VerifyFetch()

        #Upon confirmation, we call MakeMainFile().
        if userConfirms is True:
            MakeMainFile(mainPage)

        else:
            #This assumes that the user is entering the link to set the variable.
            print('Please, verify my primary link for accuracy and its IP Address for functionality.')
            sys.exit(0)


#Here, the user is able to verify that the source code for the primary page matches the page they are looking for.
#It isn't really necessary to read the whole of the source code, so much as glance to see that it's the correct site.
def VerifyFetch():

    userConfirms = raw_input('Is this the expected output? (y/n):  ')
    userConfirms = userConfirms.strip().lower()

    if userConfirms == 'y':
        print 'yes'
        return True
    #elif userConfirms == 'Y':
        #print 'Yes'
        #return True
    else:
        print 'no'
        return False

#Parse for and create title of file.  
def MakeMainFile(mainPage):

    print('Parsing title information...')
    titleText = re.search('<title>(.*)</title>', mainPage)
    titleSplitText = titleText.group(1)
    mainTitle = re.sub(r'[ :]', '', titleSplitText)
    mainFile = open(mainTitle, 'w+')
    mainFile.write(mainPage)
    mainFile.close()
    ParseMainFile(mainTitle)

def ParseMainFile(mainTitle):

    global stem

    with open(mainTitle, 'r+') as parsingFile:
        #x is my counter. If you don't like it...
        #x is still my counter.
        x = 0
        for line in parsingFile.readlines():
            searchTerm = raw_input('Searching for Url branches, please insert your search terms.  Should be in typical url directory format with (.*) for variable terms.')
            findUrlBranch = re.search(searchTerm, line)
            if findUrlBranch == None:
                print('Skipping Line: '+str(x))
            else:
                parseUrlBranch = findUrlBranch.group(1)
                print('Branch:  '+parseUrlBranch)
                scndPageUrl = stem+parseUrlBranch+'/'
                scndPageResponse = urllib2.urlopen(scndPageUrl)
                scndPage = scndPageResponse.read()
                if scndPageResponse == None:
                    doNothing = 'Do nothing.'
                else:
                    scndPageTitle = 'urlBranchlvl2_'+str(x)
                    scndPageFile = open(scndPageTitle, 'w+')
                    scndPageFile.write(scndPage)
                    scndPageFile.close()
                    ParseSecondary(scndPageTitle)

            x += 1

def ParseSecondary(scndPageTitle):

    with open(scndPageTitle, 'r+') as parsingFile:
        x = 0
        print('Parsing for URLs available.')
        for line in parsingFile.readlines():
            parseUrlBranch = re.search('href="(.*)/"', line)
            # 'None' parameter needs to be handled, so do nothing.
            if parseUrlBranch == None:
                nothing = 'do nothing'
            else:
                possibleMatch = parseUrlBranch.group(1)
                PossibleMatch(possibleMatch)
            x += 1

def PossibleMatch(possibleMatch):

    global stem
    stem = raw_input('Enter the base url for the website from which we are parsing various segments.')
    findUrl = stem+possibleMatch+'/'

    with open('PossibleMatches', 'a') as usingFile:
        try:
            wellDoesIt = urllib2.urlopen(findUrl)
            urlList = wellDoesIt.read()
            usingFile.write(possibleMatch+'\n')
            usingFile.close()
        except urllib2.HTTPError:
            print('404 Error for '+findUrl)
        except urllib2.URLError:
            print('URL Error for '+findUrl)

def FindNumbers():
	
    global stem
    usingFile = open('PossibleMatches', 'r+')
    parsingFile = usingFile.readlines()

    for line in parsingFile:
        findNumbers = 'page'
        if findNumbers in line:
            urlPiece = line.strip('\n')
            tryUrl = stem+urlPiece+'/'
            try:
                nextPages = urllib2.urlopen(tryUrl)
                foundPages = nextPages.read()
                nextMatches = open('NextMatches', 'a')
                nextMatches.write(foundPages+'\n')
                nextMatches.close()
                usingFile.close()
            except urllib2.HTTPError:
                print('404 Error for '+tryUrl)
            except urllib2.URLError:
                print('URL Error for '+tryUrl)

def FindTV():

    #Enhancements for increased useage purposes, left off with this function.
    global yourDir
    usingFile = 'PossibleMatches'
    secondaryFile = 'NextMatches'
    newLine = '\n'

    with open(usingFile, 'r+') as thisFile:
        for line in thisFile.readlines():
            parseURL = re.search('/cgi(.*)\n', line)
            if parseURL == None:
                nothing = 'do nothing'
            else:
                actualData = parseURL.group(1)
                if 'tv' in actualData or 'TV' in actualData:
                    with open('TVMatches', 'a') as tvMatch:
                        tvMatch.write(actualData+newLine)
                else:
                    doNothing = 'do nothing'	

    with open(secondaryFile, 'r+') as thatFile:
        for nLine in thatFile.readlines():
            parseURL = re.search('/cgi(.*)/"', nLine)
            if parseURL == None:
                nothing = 'do nothing'
            else:
                actualData = parseURL.group(1)
                print(actualData)
                if 'tv' in actualData or 'TV' in actualData:
                    with open('TVMatches', 'a') as tvMatch:
                        tvMatch.write(actualData+newLine)
                else:
                   doNothing = 'do nothing'

    for file in os.listdir(yourDir):
        if re.search('urlBranch(.*)', file):
            with open(file, 'r+') as thereFile:
                for uLine in thereFile.readlines():
                    parseTV = re.search('href"(.*)/"', uLine)
                    if parseTV == None:
                        nothing = 'do nothing again'
                    else:
                        actualData = parseURL.group(1)
                        print(actualData)
                        if 'tv' in actualData or 'TV' in actualData:
                            with open('TVMatches', 'a') as tvMatch:
                                tvMatch.write(actualData+newLine)
                        else:
                            doNothing = 'do nothing'

def CreateHexesFiles():

    stem = ('http://www.remotecentral.com/cgi')
    x = 1

    with open('TVMatches', 'r+') as usingFile:
        for line in usingFile:
            usingURL = stem+line
            try:
                codeURL = urllib2.urlopen(usingURL)
                codeSource = codeURL.read()
                fileName = 'Hexes'+str(x)
                with open(fileName, 'w+') as usingFile:
                    usingFile.write(codeSource)
                    x += 1
            except urllib2.HTTPError:
                print('HTTP Error')
            except urllib2.URLError:
                print('URL Error')

def ParseHexesFiles():

    global yourDir
    searchTerms = ['Power', 'On', 'Off']

    for file in os.listdir(yourDir):
        if re.search('Hexes(.*)', file):
            with open(file, 'r+') as parsingFile:
                for line in parsingFile.readlines():
                    for word in searchTerms:
                        searchFile = re.search(word+'(.*)', line)
                        if searchFile == None:
                            doNothing = 'do nothing'
                        else:
                            with open('Results', 'a+') as resultFile:
                                foundTerms = searchFile.group(1)
                                resultFile.write(foundTerms+'\n')
        else:
            doNothing = 'do nothing again'

def DestroyFiles():

    global yourDir
    destroyThings = raw_input('Do you wish to destroy your garbage?')
    userConfirms = destroyThings.strip().lower()

    if destroyThings == 'y':
        for file in os.listdir(yourDir):
            if re.search('urlBranch(.*)', file):
                os.remove(os.path.join(yourDir, file))
            elif re.search('Hexes(.*)', file):
                os.remove(os.path.join(yourDir, file))
            else:
                 doNothing = 'do nothing'
    else:
        sys.exit(0)

if __name__ == '__main__':
    sys.exit(RunProgram())
